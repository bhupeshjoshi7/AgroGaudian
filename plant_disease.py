# -*- coding: utf-8 -*-
"""Plant-disease.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e4tQE_Imd8azcjQT_m2HEedkpxJmV0rk
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("vipoooool/new-plant-diseases-dataset")

print("Path to dataset files:", path)

base_dir = '/root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'
test_dir = '/root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2/test/test'

import os
os.listdir(base_dir)

train_dir = (base_dir+ '/train')
total =0
for folder in os.listdir(train_dir):
    folder_path = os.path.join(base_dir+ '/train' ,folder)
    file_cnt =len( [file for file in os.listdir(folder_path)])
    total+=file_cnt
    print(f"Folder '{folder}' contains {file_cnt} files.")
print(f"total: {total}")

import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

training_set = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)
validation_set = tf.keras.utils.image_dataset_from_directory(
    base_dir+'/valid',
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)

cnn = tf.keras.models.Sequential()
cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))
cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
cnn.add(tf.keras.layers.Dropout(0.25))
cnn.add(tf.keras.layers.Flatten())
cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))
cnn.add(tf.keras.layers.Dropout(0.4))
#Output Layer
cnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))
cnn.compile(optimizer=tf.keras.optimizers.Adam(
    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])
cnn.summary()

training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)

train_loss, train_acc = cnn.evaluate(training_set)
print('Training accuracy:', train_acc)
val_loss, val_acc = cnn.evaluate(validation_set)
print('Validation accuracy:', val_acc)

cnn.save('trained_plant_disease_model.keras')

epochs = [i for i in range(1,11)]
plt.plot(epochs,training_history.history['accuracy'],color='red',label='Training Accuracy')
plt.plot(epochs,training_history.history['val_accuracy'],color='blue',label='Validation Accuracy')
plt.xlabel('No. of Epochs')
plt.title('Visualization of Accuracy Result')
plt.legend()
plt.show()

class_name = validation_set.class_names
test_set = tf.keras.utils.image_dataset_from_directory(
    base_dir+'/valid',
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=1,
    image_size=(128, 128),
    shuffle=False,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)

y_pred = cnn.predict(test_set)
predicted_categories = tf.argmax(y_pred, axis=1)
true_categories = tf.concat([y for x, y in test_set], axis=0)
Y_true = tf.argmax(true_categories, axis=1)
Y_true
predicted_categories

from sklearn.metrics import confusion_matrix,classification_report
cm = confusion_matrix(Y_true,predicted_categories)
print(classification_report(Y_true,predicted_categories,target_names=class_name))

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model

# Load the pre-trained ResNet50 model with imagenet weights, excluding the top layer
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))

# Freeze all layers in the base model to avoid retraining
base_model.trainable = False

# Build a new model on top of the base model
model = tf.keras.Sequential([
    base_model,  # ResNet50 as feature extractor
    GlobalAveragePooling2D(),  # Reduce the spatial dimensions
    Dropout(0.5),  # Dropout to prevent overfitting
    Dense(512, activation='relu'),  # Fully connected layer
    Dropout(0.5),
    Dense(38, activation='softmax')  # Output layer for 38 classes
])

# Compile the model with a small learning rate
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy', metrics=['accuracy'])

# Summary of the model
model.summary()

# Train the model
history = model.fit(x=training_set, validation_data=validation_set, epochs=10)

epochs = [i for i in range(1,11)]
plt.plot(epochs,history.history['accuracy'],color='red',label='Training Accuracy')
plt.plot(epochs,history.history['val_accuracy'],color='blue',label='Validation Accuracy')
plt.xlabel('No. of Epochs')
plt.title('Visualization of Accuracy Result')
plt.legend()
plt.show()

base_model_fine_tuned = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
base_model_fine_tuned.trainable = True  # Unfreeze the base model layers
fine_tune_at = 20
for layer in base_model_fine_tuned.layers[:fine_tune_at]:
    layer.trainable = False  # Freeze the layers up to the fine_tune_at

fine_tuned_model = tf.keras.Sequential([
    base_model_fine_tuned,  # ResNet50 as feature extractor
    GlobalAveragePooling2D(),  # Reduce the spatial dimensions
    Dropout(0.5),  # Dropout to prevent overfitting
    Dense(512, activation='relu'),  # Fully connected layer
    Dropout(0.5),
    Dense(38, activation='softmax')  # Output layer for 38 classes
])

fine_tuned_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy', metrics=['accuracy'])
fine_tuned_model.summary()

fine_tuned_history = fine_tuned_model.fit(x=training_set, validation_data=validation_set, epochs=10)

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model

base_model_fine_tuned = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
base_model_fine_tuned.trainable = True  # Unfreeze the base model layers
fine_tune_at = 165
for layer in base_model_fine_tuned.layers[:fine_tune_at]:
    layer.trainable = False  # Freeze the layers up to the fine_tune_at

fine_tuned_model = tf.keras.Sequential([
    base_model_fine_tuned,  # ResNet50 as feature extractor
    GlobalAveragePooling2D(),  # Reduce the spatial dimensions
    Dropout(0.5),  # Dropout to prevent overfitting
    Dense(512, activation='relu'),  # Fully connected layer
    Dropout(0.5),
    Dense(38, activation='softmax')  # Output layer for 38 classes
])

fine_tuned_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),
              loss='categorical_crossentropy', metrics=['accuracy'])
fine_tuned_model.summary()

fine_tuned_history = fine_tuned_model.fit(x=training_set, validation_data=validation_set, epochs=10)

print(len(base_model_fine_tuned.layers))

test_set = tf.keras.utils.image_dataset_from_directory(
    base_dir+'/valid',
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=1,
    image_size=(128, 128),
    shuffle=False,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)

y_pred = fine_tuned_model.predict(test_set)
predicted_categories = tf.argmax(y_pred, axis=1)
true_categories = tf.concat([y for x, y in test_set], axis=0)
Y_true = tf.argmax(true_categories, axis=1)

from sklearn.metrics import confusion_matrix,classification_report
cm = confusion_matrix(Y_true,predicted_categories)
class_name = validation_set.class_names

print(classification_report(Y_true,predicted_categories,target_names=class_name))

test_dir = '/root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2/test/test'
import os
os.listdir(test_dir)

import cv2
test_dir = '/root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2/test/test/AppleScab2.JPG'
img = cv2.imread(test_dir)
img = cv2.resize(img,(128,128))
plt.imshow(img)
img = img.reshape(1,128,128,3)

pred = fine_tuned_model.predict(img)
pred.shape
predicted_categories = tf.argmax(pred, axis=1)
predicted_categories

base_dir= '/root/.cache/kagglehub/datasets/vipoooool/new-plant-diseases-dataset/versions/2/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'
labels = training_set.class_names
labels[0]

